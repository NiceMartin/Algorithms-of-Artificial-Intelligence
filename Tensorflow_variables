tf.placeholder在声明的时候不需要初始化的数值，只需要声明类型和维数，例如
x = tf.placeholder(tf.float32, shape=(None, 1024))
tf.placeholder是为了方便定义神经网络结构，所以可以看作是符号变量。tf.placeholder通常是在训练session开始后，存放输入样本的。

tf.Variable在声明的时候必须要有初始的数值。例如
weights = tf.Variable(tf.random_normal([784, 200], stddev=0.35),name="weights")
biases = tf.Variable(tf.zeros([200]), name="biases")
tf.Variable通常是存放weight和bias，然后会不停地被更新，所以说是variable。


tf.Variable适合一些需要初始化或被训练而变化的权重或参数，而tf.placeholder适合通常不会改变的被训练的数据集。

=============================================================================================
 tf.get_variable 和tf.variable_scope

变量共享主要涉及到两个函数：

tf.get_variable(<name>, <shape>, <initializer>) 和 tf.variable_scope(<scope_name>)。

先来看第一个函数： tf.get_variable。

tf.get_variable 和tf.Variable不同的一点是，前者拥有一个变量检查机制，会检测已经存在的变量是否设置为共享变量，如果已经存在的变量没有设置为共享变量，TensorFlow 运行到第二个拥有相同名字的变量的时候，就会报错。

为了解决这个问题，TensorFlow 又提出了 tf.variable_scope 函数：它的主要作用是，在一个作用域 scope 内共享一些变量，可以有如下几种用法：

1）

with tf.variable_scope("image_filters") as scope:
    result1 = my_image_filter(image1)
    scope.reuse_variables() # or 
    #tf.get_variable_scope().reuse_variables()
    result2 = my_image_filter(image2)
    
需要注意的是：最好不要设置 reuse 标识为 False，只在需要的时候设置 reuse 标识为 True。

2)

with tf.variable_scope("image_filters1") as scope1:
    result1 = my_image_filter(image1)
with tf.variable_scope(scope1, reuse = True)
    result2 = my_image_filter(image2)
