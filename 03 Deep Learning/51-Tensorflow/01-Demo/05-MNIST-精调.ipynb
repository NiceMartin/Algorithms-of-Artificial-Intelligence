{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True) # 下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\t Training Accuracy0.94692725\t Testing Accuracy0.9508\t Learning Rate0.001\n",
      "Iter 1\t Training Accuracy0.9602727\t Testing Accuracy0.962\t Learning Rate0.00095\n",
      "Iter 2\t Training Accuracy0.9717091\t Testing Accuracy0.9692\t Learning Rate0.0009025\n",
      "Iter 3\t Training Accuracy0.9760909\t Testing Accuracy0.9713\t Learning Rate0.000857375\n",
      "Iter 4\t Training Accuracy0.9792182\t Testing Accuracy0.9721\t Learning Rate0.00081450626\n",
      "Iter 5\t Training Accuracy0.98081815\t Testing Accuracy0.9743\t Learning Rate0.0007737809\n",
      "Iter 6\t Training Accuracy0.98112726\t Testing Accuracy0.9745\t Learning Rate0.0007350919\n",
      "Iter 7\t Training Accuracy0.98449093\t Testing Accuracy0.9776\t Learning Rate0.0006983373\n",
      "Iter 8\t Training Accuracy0.9857818\t Testing Accuracy0.978\t Learning Rate0.0006634204\n",
      "Iter 9\t Training Accuracy0.9876\t Testing Accuracy0.978\t Learning Rate0.0006302494\n",
      "Iter 10\t Training Accuracy0.98892725\t Testing Accuracy0.98\t Learning Rate0.0005987369\n",
      "Iter 11\t Training Accuracy0.98874545\t Testing Accuracy0.9783\t Learning Rate0.0005688001\n",
      "Iter 12\t Training Accuracy0.9868909\t Testing Accuracy0.9783\t Learning Rate0.0005403601\n",
      "Iter 13\t Training Accuracy0.9905273\t Testing Accuracy0.979\t Learning Rate0.0005133421\n",
      "Iter 14\t Training Accuracy0.9922182\t Testing Accuracy0.9797\t Learning Rate0.000487675\n",
      "Iter 15\t Training Accuracy0.99218184\t Testing Accuracy0.9794\t Learning Rate0.00046329122\n",
      "Iter 16\t Training Accuracy0.99161816\t Testing Accuracy0.9793\t Learning Rate0.00044012666\n",
      "Iter 17\t Training Accuracy0.99307275\t Testing Accuracy0.981\t Learning Rate0.00041812033\n",
      "Iter 18\t Training Accuracy0.9898546\t Testing Accuracy0.9771\t Learning Rate0.00039721432\n",
      "Iter 19\t Training Accuracy0.99256366\t Testing Accuracy0.9807\t Learning Rate0.0003773536\n",
      "Iter 20\t Training Accuracy0.9930182\t Testing Accuracy0.9793\t Learning Rate0.00035848594\n",
      "Iter 21\t Training Accuracy0.9930182\t Testing Accuracy0.9818\t Learning Rate0.00034056162\n",
      "Iter 22\t Training Accuracy0.99396366\t Testing Accuracy0.9805\t Learning Rate0.00032353355\n",
      "Iter 23\t Training Accuracy0.9933636\t Testing Accuracy0.9792\t Learning Rate0.00030735688\n",
      "Iter 24\t Training Accuracy0.9938545\t Testing Accuracy0.9807\t Learning Rate0.000291989\n",
      "Iter 25\t Training Accuracy0.9944182\t Testing Accuracy0.9809\t Learning Rate0.00027738957\n",
      "Iter 26\t Training Accuracy0.9929091\t Testing Accuracy0.9804\t Learning Rate0.0002635201\n",
      "Iter 27\t Training Accuracy0.9948909\t Testing Accuracy0.9808\t Learning Rate0.00025034408\n",
      "Iter 28\t Training Accuracy0.9943454\t Testing Accuracy0.9812\t Learning Rate0.00023782688\n",
      "Iter 29\t Training Accuracy0.9938909\t Testing Accuracy0.9804\t Learning Rate0.00022593554\n",
      "Iter 30\t Training Accuracy0.99432725\t Testing Accuracy0.9805\t Learning Rate0.00021463877\n"
     ]
    }
   ],
   "source": [
    "# 批次大小\n",
    "batch_size = 100\n",
    "number_neural = 500\n",
    "number_neural_1 = 300\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size # // 整除\n",
    "\n",
    "# 定义两个 placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # None 表示任意维度\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.Variable(0.001, dtype=tf.float32) # tf.assign\n",
    "\n",
    "# 创建一个简单的神经网络\n",
    "W_1 = tf.Variable(tf.truncated_normal([784,number_neural], stddev=0.1)) # 截断的正太分布\n",
    "b_1 = tf.Variable(tf.zeros([number_neural])+0.1) # 初始化偏置值为0.1\n",
    "L_1 = tf.nn.tanh(tf.matmul(x, W_1) + b_1)\n",
    "L_1_dropout = tf.nn.dropout(L_1, keep_prob) # keep_prob = 0.8 80% 的神经元工作\n",
    "\n",
    "W_2 = tf.Variable(tf.truncated_normal([number_neural,number_neural_1], stddev=0.1)) # 截断的正太分布\n",
    "b_2 = tf.Variable(tf.zeros([number_neural_1])+0.1) # 初始化偏置值为0.1\n",
    "L_2 = tf.nn.tanh(tf.matmul(L_1_dropout, W_2) + b_2)\n",
    "L_2_dropout = tf.nn.dropout(L_2, keep_prob) # keep_prob = 0.8 80% 的神经元工作\n",
    "\n",
    "# 输出层\n",
    "W_3 = tf.Variable(tf.truncated_normal([number_neural_1,10], stddev=0.1)) # 截断的正太分布\n",
    "b_3 = tf.Variable(tf.zeros([10])+0.1) # 初始化偏置值为0.1\n",
    "\n",
    "predict = tf.nn.softmax(tf.matmul(L_2_dropout,W_3)+b_3)\n",
    "\n",
    "# softmax\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=predict))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss) # 收敛速度会比SGD快\n",
    "# lr 设置为 1e-2 时 结果较差, 92% 左右震荡, 不能进一步收敛\n",
    "# lr 设置为 1e-5 时 初始结果较差, 66% , 收敛速度较慢, 但个batch 训练时间长\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个bool 型列表中\n",
    "# tf.argmax(variable, axis) axis = 0 在列中找最大的数, axis = 1 在行中找最大的数\n",
    "# tf.equal https://blog.csdn.net/yjk13703623757/article/details/77251042\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(predict,1)) # tf.equal \n",
    "# 求准确率\n",
    "arruracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31):\n",
    "        \n",
    "        sess.run(tf.assign(lr, 0.001*(0.95**epoch)))\n",
    "        \n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size=batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys, keep_prob:1.0})\n",
    "        \n",
    "        learning_rate = sess.run(lr)\n",
    "        \n",
    "        train_acc = sess.run(arruracy, feed_dict={x:mnist.train.images, y:mnist.train.labels, keep_prob:0.8})# 70% 工作\n",
    "        test_acc = sess.run(arruracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})# 测试的时候所有的神经元都工作\n",
    "        print(\"Iter \" + str(epoch) + \"\\t Training Accuracy\" + str(train_acc) + \"\\t Testing Accuracy\" + str(test_acc) + \"\\t Learning Rate\" + str(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
